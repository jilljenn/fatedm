We host a 1-day workshop colocated with the [EDM 2020](http://educationaldatamining.org/edm2020/) conference.

# Motivation

Educational Data Mining is no longer a research idea.  It is common practice. Schools and service providers now routinely amass rich datasets reflecting learning behaviors and educational outcomes at the student, class, school and even district/institutional level. This data is used to support personalized instruction, guide pedagogical practice, allocate institutional resources, and support system development. This automation represents both the opportunity to benefit huge populations at low cost, and the risk to lose control over the intended outcomes, particularly as educators themselves become increasingly dependent on often opaque models. 

All models are imperfect and as recent experiences have shown, educational applications of AI are not immune to the risks observed in other domains.  Teachers, students, and parents have protested the use of educational systems in classrooms across the US, driven in part by a lack of clear guidance on how the systems are managed, and a lack of clear criteria on how they can be judged (NEP 2018, Bowles 2019, Herold 2019).  In complex educational environments problems such as bias can go undetected in real time and may, over the long term and large scale, far outweigh the potential benefits (Buckingham & Shum 2018).
 
This rapidly-growing environment raises a number of crucial ethical, research, and policy issues (Holmes et al. 2018, Lynch 2017).  Among these, how do we identify and ameliorate bias in our algorithms?  How do we address the problem identified by Barocas & Hardt in their NeurIPS 2017 tutorial: “Different models with the same reported accuracy can have a very different distribution of error across population”? How do we design systems that are accountable to social and policy concerns (Kroll et al. 2017)?  How do we ensure student privacy (e.g. Aggrawal and Yu 2008, Dwork 2006)?  How do we ensure fairness in educational systems (Holstein & Doroudi 2019, Holstein et al. 2019)?  How do we address the inevitable ethical challenges (Holmes et al. 2018, Ben-Porath & Ben Shahar 2017)? And who really owns the data (Lynch 2017)?

The goal of this workshop is to develop a focus on Fairness, Accountability, & Transparency in Educational Data (FATED).  This will include discussion of open issues in EDM, and prior research on fairness accountability and transparency in machine learning systems.  It will also include the presentation of novel peer-reviewed research by the EDM community, and a practical tutorial on some methods for assessing bias in trained models.  Finally we will work to develop near and long-term goals for the community.

# Venue

The FATED workshop will be held in Ifrane, Morocco.

# Important Dates

May 15 – [AoE](https://www.timeanddate.com/time/zones/aoe)

:   Submission of original research & position papers

June 1

:   Notification for acceptance

June 15

:   Camera-ready version due

July 10

:   FATED Workshop

# Call for Papers

Short position papers

:    Between 2 and 3 pages

Full papers

:    Between 3 and 5 pages including references

Submissions can be made through [EasyChair](https://easychair.org/my/conference?conf=fated2020).

# Workshop Chairs

Nigel Bosch (University of Illinois at Urbana-Champaign)  
Christopher Brooks  
Shayan Doroudi (University of California Irvine)  
Josh Gardner  
Kenneth Holstein (Carnegie Mellon University)  
Andrew Lan  
Collin Lynch (North Carolina State University)  
Beverly Park Woolf  
Mykola Pechenizkiy (Eindhoven University of Technology, The Netherlands)  
Steven Ritter (Carnegie Learning)  
Jill-Jênn Vie (Inria Lille, France)  
Renzhe Yu
